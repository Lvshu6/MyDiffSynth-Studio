import torch
from PIL import Image
from diffsynth.utils.data import save_video, VideoData
from diffsynth.core import load_state_dict
from diffsynth.pipelines.wan_video import WanVideoPipeline, ModelConfig
from modelscope import dataset_snapshot_download
from pathlib import Path
import os

# ================== é…ç½®è·¯å¾„ ==================
input_folder = Path("data/test")          # åŸå§‹è§†é¢‘æ‰€åœ¨ç›®å½•
flow_base = input_folder           # flow çš„æ ¹ç›®å½•ï¼ˆä¸ä½ åŸä»£ç ä¸€è‡´ï¼‰
flow_subdir = Path("flow_line")                 # flow å­ç›®å½•å
output_folder = Path("valid/5B/e30")                   # è¾“å‡ºç›®å½•
lora_path = "models/train/Wan2.2-TI2V-5B_lora/0115-1635/epoch-30.safetensors"

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
output_folder.mkdir(parents=True, exist_ok=True)
DEVICE = "cuda"
# ================== åŠ è½½æ¨¡å‹ ==================
print("Loading model...")
pipe = WanVideoPipeline.from_pretrained(
    torch_dtype=torch.bfloat16,
    device=DEVICE,
    model_configs=[
        ModelConfig(model_id="Wan-AI/Wan2.2-TI2V-5B", origin_file_pattern="models_t5_umt5-xxl-enc-bf16.pth", offload_device="cpu"),
        ModelConfig(model_id="Wan-AI/Wan2.2-TI2V-5B", origin_file_pattern="diffusion_pytorch_model*.safetensors", offload_device="cpu"),
        ModelConfig(model_id="Wan-AI/Wan2.2-TI2V-5B", origin_file_pattern="Wan2.2_VAE.pth", offload_device="cpu"),
    ],
)

# åŠ è½½ LoRA å’Œ flow adapter
state_dict = load_state_dict(lora_path)
lora_state_dict = {}
flow_adapter_state_dict = {}
for key, value in state_dict.items():
    if key.startswith("flow_line_patch_embedding.") or key.startswith("flow_line_blocks."):
        flow_adapter_state_dict[key] = value
    else:
        lora_state_dict[key] = value

pipe.flow_line_adapter.load_state_dict(flow_adapter_state_dict)
pipe.flow_line_adapter.to(DEVICE)
pipe.load_lora(pipe.dit, alpha=1, state_dict=lora_state_dict)
print("Model loaded.")

# ================== æ‰¹é‡å¤„ç† ==================
video_extensions = {".mp4", ".avi", ".mov", ".mkv"}  # æ”¯æŒçš„è§†é¢‘æ ¼å¼

for video_path in input_folder.iterdir():
    if video_path.suffix.lower() not in video_extensions:
        continue

    print(f"\nProcessing: {video_path.name}")

    # æ„é€  flow è·¯å¾„ï¼šbase / flow / video_name
    flow_path = flow_base / flow_subdir / video_path.name
    if not flow_path.exists():
        print(f"âš ï¸ Flow file not found: {flow_path}, skipping.")
        continue

    try:
        # åŠ è½½è§†é¢‘å’Œ flow
        video_data = VideoData(video_path)
        flow_data = VideoData(flow_path)

        if len(video_data) == 0 or len(flow_data) == 0:
            print(f"âš ï¸ Empty video or flow, skipping: {video_path.name}")
            continue

        img_width, img_height = video_data[0].size
        num_frames = len(video_data)

        # æ¨ç†
        generated_video = pipe(
            prompt="move",
            negative_prompt="",
            input_image=video_data[0],
            flow_line=flow_data,
            seed=0,
            tiled=True,
            height=img_height,
            width=img_width,
            num_inference_steps=20,
            num_frames=num_frames
        )

        # ä¿å­˜
        output_path = output_folder / video_path.name
        save_video(generated_video, output_path, fps=15, quality=5)
        print(f"âœ… Saved: {output_path}")

    except Exception as e:
        print(f"âŒ Error processing {video_path.name}: {e}")
        continue

print("\nğŸ‰ Batch processing completed.")